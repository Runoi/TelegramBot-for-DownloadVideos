import os
import re
import asyncio
import logging
from datetime import datetime
from functools import lru_cache
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service as ChromeService
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from aiogram.types import Message
from dotenv import load_dotenv
import yt_dlp
import aiohttp
from bs4 import BeautifulSoup

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("video_bot.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

load_dotenv('token.env')

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è 
BOT_TOKEN = os.getenv('BOT_TOKEN')
VK_ACCESS_TOKEN = os.getenv('VK_ACCESS_TOKEN')
VK_API_VERSION = '5.199'
DOWNLOAD_DIR = "downloads"
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
SELENIUM_REMOTE_URL = os.getenv('SELENIUM_REMOTE_URL')
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
PLATFORMS = {
    "youtube": r"(youtube\.com|youtu\.be)",
    "instagram": r"instagram\.com",
    "tiktok": r"tiktok\.com|vm\.tiktok\.com",
    "twitter": r"(x\.com|twitter\.com)",
    "vk": r"vk\.com",
    "reddit": r"(reddit\.com|packaged-media\.redd\.it)",
}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

@lru_cache(maxsize=100)
def normalize_twitter_url(url: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π Twitter"""
    if not url or 'pbs.twimg.com' not in url:
        return url
    
    base = url.split('?')[0]
    return f"{base}?name=orig"

def get_selenium_driver():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞ Selenium —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π ChromeDriver"""
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("user-agent=Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1")
    
    if SELENIUM_REMOTE_URL:
        return webdriver.Remote(
            command_executor=SELENIUM_REMOTE_URL,
            options=options
        )
    else:
        service = ChromeService(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        driver.set_page_load_timeout(30)
        driver.implicitly_wait(10)
        return driver

def clean_downloads():
    """–û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∑–∞–≥—Ä—É–∑–æ–∫"""
    for file in os.listdir(DOWNLOAD_DIR):
        file_path = os.path.join(DOWNLOAD_DIR, file)
        try:
            if os.path.isfile(file_path):
                os.unlink(file_path)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")

async def download_twitter_image(url: str, filename: str) -> str:
    """–°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å Twitter"""
    try:
        base_url = url.split('?')[0]
        qualities = ['orig', 'large', 'medium', 'small']
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1',
            'Referer': 'https://twitter.com/',
            'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8'
        }
        
        async with aiohttp.ClientSession(headers=headers) as session:
            for quality in qualities:
                try:
                    img_url = f"{base_url}?format=jpg&name={quality}"
                    async with session.get(img_url, timeout=10) as response:
                        if response.status == 200:
                            filepath = os.path.join(DOWNLOAD_DIR, filename)
                            with open(filepath, 'wb') as f:
                                async for chunk in response.content.iter_chunked(1024):
                                    f.write(chunk)
                            return filepath
                except:
                    continue
            
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∏ –≤ –æ–¥–Ω–æ–º –∫–∞—á–µ—Å—Ç–≤–µ")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ Twitter –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {url}: {str(e)}")
        raise

async def download_image(url: str, filename: str) -> str:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    if 'pbs.twimg.com' in url:
        return await download_twitter_image(url, filename)
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        async with aiohttp.ClientSession(headers=headers) as session:
            async with session.get(url, timeout=10) as response:
                if response.status == 200:
                    filepath = os.path.join(DOWNLOAD_DIR, filename)
                    with open(filepath, 'wb') as f:
                        async for chunk in response.content.iter_chunked(1024):
                            f.write(chunk)
                    return filepath
                raise ValueError(f"HTTP –æ—à–∏–±–∫–∞: {response.status}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {url}: {str(e)}")
        raise

async def get_vk_post(url: str) -> dict:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–∞ –í–ö–æ–Ω—Ç–∞–∫—Ç–µ —á–µ—Ä–µ–∑ API"""
    try:
        match = re.search(r'wall(-?\d+)_(\d+)', url)
        if not match:
            raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π URL –ø–æ—Å—Ç–∞ VK")
        
        owner_id, post_id = match.groups()
        
        params = {
            'access_token': VK_ACCESS_TOKEN,
            'v': VK_API_VERSION,
            'posts': f"{owner_id}_{post_id}",
            'extended': 1,
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get('https://api.vk.com/method/wall.getById', params=params) as response:
                data = await response.json()
                
                if 'error' in data:
                    raise ValueError(f"VK API error: {data['error']['error_msg']}")
                
                post = data['response']['items'][0]
                post_text = post.get('text', '')
                
                attachments = post.get('attachments', [])
                images = []
                
                for attachment in attachments:
                    if attachment['type'] == 'photo':
                        photo = attachment['photo']
                        sizes = photo.get('sizes', [])
                        if sizes:
                            max_size = max(sizes, key=lambda x: x.get('width', 0))
                            images.append(max_size['url'])
                    elif attachment['type'] == 'video':
                        video = attachment['video']
                        if 'image' in video:
                            images.extend([
                                img['url'] for img in video['image'] 
                                if isinstance(img, dict) and 'url' in img
                            ])
                
                return {
                    'text': post_text,
                    'images': images[:10]
                }
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ VK API: {str(e)}")
        raise

async def try_nitter(url: str) -> dict:
    """–ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ Nitter"""
    try:
        nitter_url = url.replace('twitter.com', 'nitter.net').replace('x.com', 'nitter.net')
        headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1'
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(nitter_url, headers=headers, timeout=10) as response:
                text = await response.text()
                soup = BeautifulSoup(text, 'html.parser')

                tweet_text = ""
                content_div = soup.find('div', class_='tweet-content')
                if content_div:
                    tweet_text = content_div.get_text('\n').strip()

                images = []
                videos = []
                gallery = soup.find('div', class_='attachments')
                if gallery:
                    for img in gallery.find_all('img'):
                        if img.get('src'):
                            img_url = img['src']
                            if img_url.startswith('/pic/'):
                                img_url = f'https://nitter.net{img_url}'
                            images.append(img_url)
                    
                    for video in gallery.find_all('video'):
                        if video.get('src'):
                            videos.append(video['src'])
                        for source in video.find_all('source'):
                            if source.get('src'):
                                videos.append(source['src'])

                return {
                    'success': bool(tweet_text or images or videos),
                    'data': {
                        'text': tweet_text,
                        'images': images[:4],
                        'videos': videos[:2]
                    }
                }
    except Exception as e:
        logger.warning(f"Nitter –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {str(e)}")
        return {'success': False}

async def get_twitter_video_url(driver, url: str) -> str:
    """–ü–æ–ª—É—á–∞–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ Selenium"""
    try:
        driver.get(url)
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.XPATH, '//video'))
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –≤–∏–¥–µ–æ —ç–ª–µ–º–µ–Ω—Ç—ã
        videos = driver.find_elements(By.XPATH, '//video')
        for video in videos:
            try:
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å src –∏–ª–∏ source
                video_url = video.get_attribute('src')
                if video_url and not video_url.startswith('blob:'):
                    return video_url
                
                # –ò—â–µ–º source –≤–Ω—É—Ç—Ä–∏ video
                sources = video.find_elements(By.XPATH, './/source')
                for source in sources:
                    source_url = source.get_attribute('src')
                    if source_url and not source_url.startswith('blob:'):
                        return source_url
            except:
                continue
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ - –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ data-–∞—Ç—Ä–∏–±—É—Ç–æ–≤
        for video in videos:
            try:
                video_url = video.get_attribute('data-video-url')
                if video_url:
                    return video_url
            except:
                continue
        
        return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –≤–∏–¥–µ–æ URL: {str(e)}")
        return None

async def download_twitter_video(url: str) -> str:
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Å Twitter —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º yt-dlp –∏ –æ–±—Ö–æ–¥–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤"""
    clean_downloads()
    ydl_opts = {
        'outtmpl': f'{DOWNLOAD_DIR}/%(title)s.%(ext)s',
        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',
        'quiet': False,
        'no_warnings': False,
        'retries': 3,
        'logger': logger,
        'extract_flat': True,
    }
    
    try:
        # –ü—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å —á–µ—Ä–µ–∑ yt-dlp —Å –æ–±—Ö–æ–¥–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏
        logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ —Å–∫–∞—á–∞—Ç—å —á–µ—Ä–µ–∑ yt-dlp: {url}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è Twitter
        ydl_opts['extractor_args'] = {
            'twitter': {
                'username': os.getenv('TWITTER_USERNAME'),
                'password': os.getenv('TWITTER_PASSWORD')
            }
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)
            filename = ydl.prepare_filename(info)
            
            if os.path.exists(filename):
                return filename
            
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥
            files = [f for f in os.listdir(DOWNLOAD_DIR) 
                    if f.endswith('.mp4') and os.path.isfile(os.path.join(DOWNLOAD_DIR, f))]
            if files:
                return os.path.join(DOWNLOAD_DIR, files[0])
            
            raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª")
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –≤–∏–¥–µ–æ: {str(e)}")
        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ: {str(e)}")

async def extract_media_urls(driver) -> dict:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ URL –≤—Å–µ—Ö –º–µ–¥–∏–∞ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–¥–µ–æ, –≥–∏—Ñ–∫–∏)"""
    media_urls = []
    video_urls = []
    
    # 1. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    try:
        img_elements = driver.find_elements(By.XPATH,
            '//div[@data-testid="tweetPhoto"]//img | '
            '//div[contains(@class, "media-image")]//img')
        
        for img in img_elements:
            try:
                src = img.get_attribute('src') or img.get_attribute('srcset')
                if src and not src.startswith('blob:'):
                    if ',' in src:
                        src = src.split(',')[-1].strip().split()[0]
                    base_url = src.split('?')[0]
                    media_urls.append(f"{base_url}?name=orig")
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {str(e)}")

    # 2. –í–∏–¥–µ–æ –∏ GIF - –∏—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–≤–∏—Ç —Å –≤–∏–¥–µ–æ
    try:
        video_links = driver.find_elements(By.XPATH,
            '//a[contains(@href, "/status/") and contains(@href, "/video/")]')
        
        for link in video_links:
            try:
                href = link.get_attribute('href')
                if href and 'twitter.com' in href:
                    video_urls.append(href)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ-—Å—Å—ã–ª–∫–∏: {str(e)}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤–∏–¥–µ–æ-—Å—Å—ã–ª–æ–∫: {str(e)}")

    # 3. –ú–µ—Ç–∞-—Ç–µ–≥–∏ (OpenGraph)
    try:
        meta_images = driver.find_elements(By.XPATH,
            '//meta[@property="og:image"] | '
            '//meta[@name="twitter:image"]')
        
        for meta in meta_images:
            try:
                img_url = meta.get_attribute('content')
                if img_url and img_url not in media_urls and not img_url.startswith('blob:'):
                    media_urls.append(img_url)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ meta-—Ç–µ–≥–∞: {str(e)}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ meta-—Ç–µ–≥–æ–≤: {str(e)}")

    return {
        'images': media_urls,
        'videos': list(set(video_urls))  # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    }

async def try_selenium_parsing(url: str) -> dict:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ Twitter/X —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ç–≤–∏—Ç–æ–≤ –±–µ–∑ —Ç–µ–∫—Å—Ç–∞"""
    driver = None
    try:
        driver = get_selenium_driver()
        driver.get(url)
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.TAG_NAME, 'article')))
        
        # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ–¥–∏–∞
        driver.execute_script("window.scrollBy(0, 500);")
        await asyncio.sleep(2)

        tweet_text = ""
        try:
            # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ —Ç–µ–∫—Å—Ç–∞
            text_elements = driver.find_elements(By.XPATH, 
                '//div[@data-testid="tweetText"] | '
                '//div[contains(@class, "tweet-text")] | '
                '//div[@lang]')
            
            for elem in text_elements:
                if elem.text.strip():
                    tweet_text = elem.text
                    break
        except Exception as e:
            logger.warning(f"–¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {str(e)}")

        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –º–µ–¥–∏–∞
        media_data = await extract_media_urls(driver)
        
        return {
            'success': bool(tweet_text or media_data['images'] or media_data['videos']),
            'data': {
                'text': tweet_text,
                'images': media_data['images'][:10],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                'videos': media_data['videos'][:3]    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∏–¥–µ–æ
            }
        }
    except Exception as e:
        logger.error(f"Selenium –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {str(e)}")
        return {'success': False}
    finally:
        if driver:
            driver.quit()

async def get_twitter_post(url: str) -> dict:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤ Twitter/X"""
    try:
        nitter_data = await try_nitter(url)
        if nitter_data['success']:
            return nitter_data['data']

        selenium_data = await try_selenium_parsing(url)
        if selenium_data['success']:
            return selenium_data['data']

        raise ValueError("–í—Å–µ –º–µ—Ç–æ–¥—ã –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ Twitter/X: {str(e)}")
        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ—Å—Ç–∞. Twitter/X –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø.")

def get_ydl_opts(url: str) -> dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º"""
    base_opts = {
        'outtmpl': f'{DOWNLOAD_DIR}/%(title)s.%(ext)s',
        'quiet': False,
        'no_warnings': False,
        'retries': 3,
        'logger': logger,
        'merge_output_format': 'mp4',
        'postprocessors': [{
            'key': 'FFmpegVideoConvertor',
            'preferedformat': 'mp4',
        }]
    }

    if re.search(PLATFORMS["twitter"], url, re.IGNORECASE):
        return {
            **base_opts,
            'format': 'bv*[ext=mp4][vcodec!=av01]+ba[ext=m4a]/b[ext=mp4]/b',
        }
    
    if re.search(PLATFORMS["instagram"], url, re.IGNORECASE):
        return {
            **base_opts,
            'format': 'bv*[vcodec!=av01]+ba/b[vcodec!=av01]',
            'socket_timeout': 30,
            'force_ipv4': True,
        }

    return {
        **base_opts,
        'format': 'bv*[height<=720][ext=mp4][vcodec!=av01]+ba/b[height<=720][vcodec!=av01]',
    }

async def compress_video(input_path: str, output_path: str, crf: int = 28) -> bool:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ FFmpeg"""
    try:
        logger.info(f"–°–∂–∞—Ç–∏–µ –≤–∏–¥–µ–æ: {input_path} -> {output_path}")
        
        process = await asyncio.create_subprocess_exec(
            'ffmpeg',
            '-i', input_path,
            '-vf', 'scale=1280:720',
            '-vcodec', 'libx264',
            '-crf', str(crf),
            '-c:a', 'aac',
            '-b:a', '128k',
            '-preset', 'fast',
            '-movflags', '+faststart',
            '-y',
            output_path,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            logger.error(f"–û—à–∏–±–∫–∞ FFmpeg: {stderr.decode()}")
            return False
        return True
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–∂–∞—Ç–∏—è: {str(e)}")
        return False

async def download_video(url: str) -> str:
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≤–∏–¥–µ–æ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    clean_downloads()
    ydl_opts = get_ydl_opts(url)
    
    try:
        logger.info(f"–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏: {url}")
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=True)
            filename = ydl.prepare_filename(info)
            
            if not os.path.exists(filename):
                files = [f for f in os.listdir(DOWNLOAD_DIR) if os.path.isfile(os.path.join(DOWNLOAD_DIR, f))]
                if files:
                    filename = os.path.join(DOWNLOAD_DIR, files[0])
                    logger.warning(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}")
                else:
                    raise FileNotFoundError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Å–∫–∞—á–∞–Ω–Ω—ã–π —Ñ–∞–π–ª")
            
            logger.info(f"–£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ: {filename}")
            return filename
            
    except yt_dlp.DownloadError as e:
        if "Requested format is not available" in str(e):
            logger.warning("–ó–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–±—É—é –ª—é–±–æ–π –¥–æ—Å—Ç—É–ø–Ω—ã–π")
            ydl_opts['format'] = 'best'
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=True)
                filename = ydl.prepare_filename(info)
                
                if not os.path.exists(filename):
                    files = [f for f in os.listdir(DOWNLOAD_DIR) if os.path.isfile(os.path.join(DOWNLOAD_DIR, f))]
                    if files:
                        filename = os.path.join(DOWNLOAD_DIR, files[0])
                
                return filename
        raise

@dp.message(Command("start"))
async def start(message: Message):
    logger.info(f"–ù–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {message.from_user.id}")
    await message.answer(
        "üîª –û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ —Å:\n"
        "YouTube, Instagram, TikTok, Twitter/X\n"
        "VK, Reddit\n\n"
        "–ò–ª–∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –ø–æ—Å—Ç —Å:\n"
        "VK –∏–ª–∏ Twitter/X (—Ç–µ–∫—Å—Ç + –∫–∞—Ä—Ç–∏–Ω–∫–∏)\n\n"
        "–Ø —Å–∫–∞—á–∞—é –∏ –æ—Ç–ø—Ä–∞–≤–ª—é –≤–∞–º –∫–æ–Ω—Ç–µ–Ω—Ç!"
    )

async def send_media_group(message: Message, images: list, videos: list):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ –º–µ–¥–∏–∞–≥—Ä—É–ø–ø—ã —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ"""
    try:
        media_group = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        for i, img_url in enumerate(images[:10]):
            try:
                filename = f"image_{i}_{datetime.now().strftime('%Y%m%d%H%M%S')}.jpg"
                img_path = await download_image(img_url, filename)
                
                with open(img_path, 'rb') as img_file:
                    media_group.append(
                        types.InputMediaPhoto(
                            media=types.BufferedInputFile(
                                img_file.read(),
                                filename=filename
                            )
                        )
                    )
                os.remove(img_path)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {img_url}: {str(e)}")
                continue
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ –ø—Ä–µ–≤—å—é (–∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
        for i, video_url in enumerate(videos[:10 - len(media_group)]):
            try:
                filename = f"video_preview_{i}_{datetime.now().strftime('%Y%m%d%H%M%S')}.jpg"
                img_path = await download_image(video_url, filename)
                
                with open(img_path, 'rb') as img_file:
                    media_group.append(
                        types.InputMediaPhoto(
                            media=types.BufferedInputFile(
                                img_file.read(),
                                filename=filename
                            )
                        )
                    )
                os.remove(img_path)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ –ø—Ä–µ–≤—å—é {video_url}: {str(e)}")
                continue
        
        if media_group:
            await bot.send_media_group(
                chat_id=message.chat.id,
                media=media_group
            )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –º–µ–¥–∏–∞–≥—Ä—É–ø–ø—ã: {str(e)}")
        raise

async def handle_post_with_images(message: Message, post_data: dict):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å—Ç–∞ —Å –º–µ–¥–∏–∞"""
    try:
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
        if post_data.get('text'):
            await message.answer(f"üìù –¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞:\n\n{post_data['text']}")
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –º–µ–¥–∏–∞
        if post_data.get('images'):
            await send_media_group(message, post_data['images'], [])
        else:
            await message.answer("‚ÑπÔ∏è –í –ø–æ—Å—Ç–µ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤.")
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞: {str(e)}")
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ—Å—Ç–∞: {str(e)}")

async def determine_twitter_post_type(driver, url: str) -> str:
    """–¢–æ—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ Twitter –ø–æ—Å—Ç–∞ (video/photo/text)"""
    try:
        driver.get(url)
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.XPATH, '//article')))
        
        # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤–∏–¥–µ–æ-–∫–æ–Ω—Ç–µ–Ω—Ç–∞
        video_containers = driver.find_elements(By.XPATH,
            '//div[@data-testid="videoPlayer"] | '
            '//div[contains(@class, "video-container")]')
        
        if video_containers:
            return "video"
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        image_galleries = driver.find_elements(By.XPATH,
            '//div[@data-testid="tweetPhoto"] | '
            '//div[contains(@class, "media-image")]')
        
        if image_galleries:
            return "photo"
        
        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –º–µ–¥–∏–∞-–≤–ª–æ–∂–µ–Ω–∏—è
        media_tags = driver.find_elements(By.XPATH,
            '//img[contains(@src, "twimg.com/media/")] | '
            '//video[contains(@src, "twimg.com/media/")]')
        
        if media_tags:
            for tag in media_tags:
                if tag.tag_name == 'video':
                    return "video"
            return "photo"
        
        return "text"
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –ø–æ—Å—Ç–∞: {str(e)}")
        return "unknown"

async def handle_twitter_video_post(message: Message, url: str):
    """–°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ-–ø–æ—Å—Ç–æ–≤"""
    try:
        await message.answer("‚è≥ –ü—ã—Ç–∞—é—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ...")
        
        # –ü—Ä–æ–±—É–µ–º —Å–∫–∞—á–∞—Ç—å —á–µ—Ä–µ–∑ yt-dlp
        try:
            filename = await download_twitter_video(url)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = os.path.getsize(filename)
            if file_size > MAX_FILE_SIZE:
                compressed_path = f"{filename}_compressed.mp4"
                await message.answer("‚ö†Ô∏è –í–∏–¥–µ–æ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ, —Å–∂–∏–º–∞—é...")
                
                if await compress_video(filename, compressed_path):
                    compressed_size = os.path.getsize(compressed_path)
                    if compressed_size <= MAX_FILE_SIZE:
                        os.remove(filename)
                        filename = compressed_path
                    else:
                        os.remove(compressed_path)
                        raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∂–∞—Ç—å –≤–∏–¥–µ–æ")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ
            with open(filename, "rb") as video_file:
                await message.answer_video(
                    video=types.BufferedInputFile(
                        video_file.read(),
                        filename="twitter_video.mp4"
                    ),
                    caption="üé• –í–∏–¥–µ–æ –∏–∑ Twitter/X"
                )
            os.remove(filename)
            return True
            
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ (–ø–æ–ø—ã—Ç–∫–∞ 1): {str(e)}")
            await message.answer("‚ö†Ô∏è –ü–µ—Ä–≤—ã–π –º–µ—Ç–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É—é –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π...")
        
        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ Selenium
        driver = get_selenium_driver()
        try:
            driver.get(url)
            WebDriverWait(driver, 20).until(
                EC.presence_of_element_located((By.XPATH, '//video')))
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –≤–∏–¥–µ–æ
            video_element = driver.find_element(By.XPATH, '//video')
            video_url = video_element.get_attribute('src')
            
            if not video_url:
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ source
                source_element = video_element.find_element(By.XPATH, './/source')
                video_url = source_element.get_attribute('src')
            
            if video_url and video_url.startswith('http'):
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Referer': 'https://twitter.com/'
                }
                
                filename = os.path.join(DOWNLOAD_DIR, f"twitter_video_{datetime.now().timestamp()}.mp4")
                async with aiohttp.ClientSession(headers=headers) as session:
                    async with session.get(video_url) as response:
                        if response.status == 200:
                            with open(filename, 'wb') as f:
                                async for chunk in response.content.iter_chunked(1024):
                                    f.write(chunk)
                            
                            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–∏–¥–µ–æ
                            with open(filename, "rb") as video_file:
                                await message.answer_video(
                                    video=types.BufferedInputFile(
                                        video_file.read(),
                                        filename="twitter_video.mp4"
                                    ),
                                    caption="üé• –í–∏–¥–µ–æ –∏–∑ Twitter/X"
                                )
                            os.remove(filename)
                            return True
            return False
            
        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ (–ø–æ–ø—ã—Ç–∫–∞ 2): {str(e)}")
            return False
        finally:
            driver.quit()
            
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ: {str(e)}")
        return False

async def handle_twitter_post(message: Message, url: str):
    """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ Twitter –ø–æ—Å—Ç–æ–≤"""
    try:
        # –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ—Å—Ç–∞
        driver = get_selenium_driver()
        try:
            post_type = await determine_twitter_post_type(driver, url)
            await message.answer(f"‚è≥ –û–±–Ω–∞—Ä—É–∂–µ–Ω {post_type} –ø–æ—Å—Ç, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é...")

            # –î–ª—è –≤–∏–¥–µ–æ-–ø–æ—Å—Ç–æ–≤
            if post_type == "video":
                success = await handle_twitter_video_post(message, url)
                if success:
                    return
                else:
                    await message.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ, –ø–æ–∫–∞–∑—ã–≤–∞—é –ø—Ä–µ–≤—å—é...")

            # –û–±—â–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –ø–æ—Å—Ç–æ–≤
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
            tweet_text = ""
            try:
                text_elements = driver.find_elements(By.XPATH, 
                    '//div[@data-testid="tweetText"] | '
                    '//div[contains(@class, "tweet-text")] | '
                    '//div[@lang]')
                
                for elem in text_elements:
                    if elem.text.strip():
                        tweet_text = elem.text
                        break
            except:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç —Ç–≤–∏—Ç–∞")

            # –ü–æ–ª—É—á–∞–µ–º –º–µ–¥–∏–∞
            media_urls = []
            try:
                media_elements = driver.find_elements(By.XPATH,
                    '//div[@data-testid="tweetPhoto"]//img | '
                    '//div[contains(@class, "media-image")]//img | '
                    '//video[@poster]')
                
                for elem in media_elements:
                    if elem.tag_name == 'img':
                        src = elem.get_attribute('src') or elem.get_attribute('srcset')
                        if src and not src.startswith('blob:'):
                            if ',' in src:
                                src = src.split(',')[-1].strip().split()[0]
                            media_urls.append(src.split('?')[0])
                    elif elem.tag_name == 'video':
                        poster = elem.get_attribute('poster')
                        if poster:
                            media_urls.append(poster)
            except:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –º–µ–¥–∏–∞")

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if tweet_text:
                await message.answer(f"üìù –¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞:\n\n{tweet_text}")
            
            if media_urls:
                await message.answer(f"üñºÔ∏è –ú–µ–¥–∏–∞ –∏–∑ –ø–æ—Å—Ç–∞ ({len(media_urls)}):")
                await send_media_group(message, media_urls[:10], [])
            elif not tweet_text:
                await message.answer("‚ÑπÔ∏è –í –ø–æ—Å—Ç–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –º–µ–¥–∏–∞")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å—Ç–∞: {str(e)}")
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ—Å—Ç. Twitter/X –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –¥–æ—Å—Ç—É–ø.")
        finally:
            driver.quit()
            
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Twitter: {str(e)}")
        await message.answer(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}")

@dp.message(F.text)
async def handle_links(message: Message):
    url = message.text.strip()
    user_id = message.from_user.id
    logger.info(f"–ó–∞–ø—Ä–æ—Å –æ—Ç {user_id}: {url}")
    
    if url.startswith('/'):
        return
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ Twitter/X
    twitter_patterns = ['/status/', 'x.com/', 'twitter.com/']
    if re.search(PLATFORMS["twitter"], url, re.IGNORECASE) and any(p in url for p in twitter_patterns):
        await handle_twitter_post(message, url)
        return
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å—Ç–∞ VK
    vk_patterns = ['/wall', 'vk.com/wall', 'w=wall']
    if re.search(PLATFORMS["vk"], url, re.IGNORECASE) and any(p in url for p in vk_patterns):
        try:
            await message.answer("‚è≥ –ü–æ–ª—É—á–∞—é –ø–æ—Å—Ç –∏–∑ VK...")
            post_data = await get_vk_post(url)
            await handle_post_with_images(message, post_data)
            return
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ VK: {str(e)}")
            await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–æ—Å—Ç–∞ VK: {str(e)}")
            return
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ —Å –¥—Ä—É–≥–∏—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º
    if not any(re.search(pattern, url, re.IGNORECASE) for pattern in PLATFORMS.values()):
        logger.warning(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞: {url}")
        await message.answer("‚ùå –≠—Ç–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.")
        return

    try:
        await message.answer("‚è≥ –°–∫–∞—á–∏–≤–∞—é –≤–∏–¥–µ–æ...")
        filename = await download_video(url)
        
        file_size = os.path.getsize(filename)
        logger.info(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size//1024//1024}MB")
        
        if file_size > MAX_FILE_SIZE:
            compressed_path = f"{filename}_compressed.mp4"
            await message.answer("‚ö†Ô∏è –°–∂–∏–º–∞—é –≤–∏–¥–µ–æ...")
            
            if await compress_video(filename, compressed_path):
                compressed_size = os.path.getsize(compressed_path)
                logger.info(f"–†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ —Å–∂–∞—Ç–∏—è: {compressed_size//1024//1024}MB")
                
                if compressed_size > MAX_FILE_SIZE:
                    logger.warning("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –ø–æ—Å–ª–µ —Å–∂–∞—Ç–∏—è")
                    await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∂–∞—Ç—å –≤–∏–¥–µ–æ –¥–æ –¥–æ–ø—É—Å—Ç–∏–º–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞.")
                    os.remove(filename)
                    if os.path.exists(compressed_path):
                        os.remove(compressed_path)
                    return
                
                filename = compressed_path

        with open(filename, "rb") as video_file:
            logger.info("–û—Ç–ø—Ä–∞–≤–∫–∞ –≤–∏–¥–µ–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é")
            await message.answer_video(
                video=types.BufferedInputFile(
                    video_file.read(),
                    filename=os.path.basename(filename)
                ),
                caption=f"üé• {os.path.basename(filename)[:100]}"
            )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {str(e)}", exc_info=True)
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    finally:
        if 'filename' in locals() and os.path.exists(filename):
            os.remove(filename)
        if 'compressed_path' in locals() and os.path.exists(compressed_path):
            os.remove(compressed_path)

async def main():
    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞")
    await dp.start_polling(bot)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}", exc_info=True)